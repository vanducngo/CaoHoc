TOKENIZERS_PARALLELISM=false deepspeed train_llamp.py --deepspeed_config deepspeed_config/zero2_a100_40g.json --config configs/llava/zero-shot/$1_llama_7b.yml --lr_scheduler cosine --lora_rank 8 --lora_alpha 16 --lora_dropout 0.1  --naive_decoding --num_decoder_layers 1 --text_init clip --coop_num_shots 16 --name EXAMPLE_PROJECT --lr 2e-4 --num_llm_prompts 16 --prompt_type suffix --label_smoothing 0.0 --distillation_type soft --lambda_dist 2.5 --llm_prompt_depth 9 --lora_lr 2e-5 --coop_seed $2 --num_prior_token 100 --v_lora_start 6 --v_lora_end 12 --freeze_decoder_kv --freeze_decoder_ffn --visual_prompting 
