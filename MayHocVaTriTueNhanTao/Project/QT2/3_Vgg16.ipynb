{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae00008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # Directly import tqdm\n",
    "from data_loader import get_cifar100_loaders\n",
    "from evaluation_utils import (evaluate_model, plot_confusion_matrix,\n",
    "                              visualize_misclassified, get_cifar100_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873c9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs, learning_rate, device, model_name=\"vgg16\"):\n",
    "    \"\"\"Hàm huấn luyện và đánh giá model.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # SGD with momentum is often good for fine-tuning VGG\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    # A scheduler can be very helpful for VGG\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) # Reduce LR every 10 epochs\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    model_save_path = f'{model_name}_cifar100_best.pth'\n",
    "\n",
    "    train_acc_history = []\n",
    "    test_acc_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        # Training loop with tqdm progress bar\n",
    "        train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for i, (inputs, labels) in enumerate(train_iterator):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            train_iterator.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc_train = 100.0 * correct_train / total_train\n",
    "        train_acc_history.append(epoch_acc_train)\n",
    "\n",
    "        # Validation loop with tqdm progress bar\n",
    "        model.eval()\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        test_iterator = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_iterator:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_acc_test = 100.0 * correct_test / total_test\n",
    "        test_acc_history.append(epoch_acc_test)\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | '\n",
    "              f'Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc_train:.2f}% | '\n",
    "              f'Test Acc: {epoch_acc_test:.2f}% | LR: {scheduler.get_last_lr()[0]:.6f} | '\n",
    "              f'Duration: {epoch_duration:.2f}s')\n",
    "\n",
    "        scheduler.step() # Update learning rate\n",
    "\n",
    "        if epoch_acc_test > best_accuracy:\n",
    "            best_accuracy = epoch_acc_test\n",
    "            try:\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                print(f'>>> Best model saved to {model_save_path} with Test Accuracy: {best_accuracy:.2f}%')\n",
    "            except Exception as e:\n",
    "                 print(f\"Lỗi khi lưu model: {e}\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    print(f'Best Validation Accuracy achieved during training: {best_accuracy:.2f}%')\n",
    "\n",
    "    print(f\"Loading best model state from {model_save_path} for final evaluation...\")\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not load best model state: {e}. Evaluating with the final model state.\")\n",
    "\n",
    "    return model, train_acc_history, test_acc_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b93485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32 # VGG is memory intensive, might need smaller batch size\n",
    "LEARNING_RATE = 0.001   # Initial learning rate for SGD (VGG is sensitive)\n",
    "IMG_SIZE = 224          # VGG expects 224x224 input\n",
    "USE_AUGMENTATION = True\n",
    "DATA_DIR = './data_cifar100'\n",
    "NUM_WORKERS = 4\n",
    "MODEL_NAME = \"3_VGG16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7decd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cpu\n",
      "Files already downloaded and verified\n",
      "Đang tải dữ liệu CIFAR-100 (resize: 224x224)...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Đã tải xong CIFAR-100.\n",
      "Số lượng ảnh Train: 50000\n",
      "Số lượng ảnh Test: 10000\n",
      "Kích thước ảnh: 224x224\n",
      "Sử dụng Data Augmentation: True\n",
      "Khởi tạo VGG16 pre-trained model...\n",
      "Đã thay thế lớp cuối cùng của VGG classifier bằng lớp Linear(4096, 100)\n",
      "Bắt đầu fine-tuning VGG16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 7/1563 [07:07<26:23:13, 61.05s/it, loss=4.63]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# (Optional) Fine-tuning strategy: Unfreeze only the classifier or last few conv blocks\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# for param in model.features.parameters(): # Freeze feature extractor\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m#    param.requires_grad = False\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# print(\"Feature extractor frozen. Only training classifier.\")\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# optimizer = optim.SGD(model.classifier.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBắt đầu fine-tuning VGG16...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m trained_model, train_history, test_history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# --- Final Evaluation and Visualization ---\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Performing Final Evaluation on Test Set ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, test_loader, num_epochs, learning_rate, device, model_name)\u001b[39m\n\u001b[32m     30\u001b[39m outputs = model(inputs)\n\u001b[32m     31\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m optimizer.step()\n\u001b[32m     35\u001b[39m running_loss += loss.item() * inputs.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9519f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sử dụng thiết bị: {device}\")\n",
    "\n",
    "class_names = get_cifar100_class_names(DATA_DIR)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Đang tải dữ liệu CIFAR-100 (resize: {IMG_SIZE}x{IMG_SIZE})...\")\n",
    "train_loader, test_loader, _ = get_cifar100_loaders(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_dir=DATA_DIR,\n",
    "    img_size=IMG_SIZE,\n",
    "    use_augmentation=USE_AUGMENTATION,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "if train_loader is None:\n",
    "    print(\"Không thể tải dữ liệu. Kết thúc chương trình.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Khởi tạo VGG16 pre-trained model...\")\n",
    "weights = models.VGG16_BN_Weights.IMAGENET1K_V1\n",
    "model = models.vgg16_bn(weights=weights)\n",
    "\n",
    "# --- Modify the classifier for CIFAR-100 ---\n",
    "# VGG's classifier is a nn.Sequential. We'll replace the last layer.\n",
    "num_ftrs = model.classifier[6].in_features # Get input features of the last Linear layer\n",
    "model.classifier[6] = nn.Linear(num_ftrs, num_classes) # Replace the last layer\n",
    "print(f\"Đã thay thế lớp cuối cùng của VGG classifier bằng lớp Linear({num_ftrs}, {num_classes})\")\n",
    "\n",
    "# (Optional) Fine-tuning strategy: Unfreeze only the classifier or last few conv blocks\n",
    "# for param in model.features.parameters(): # Freeze feature extractor\n",
    "#    param.requires_grad = False\n",
    "# print(\"Feature extractor frozen. Only training classifier.\")\n",
    "# optimizer = optim.SGD(model.classifier.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "print(\"Bắt đầu fine-tuning VGG16...\")\n",
    "trained_model, train_history, test_history = train_model(\n",
    "    model, train_loader, test_loader, NUM_EPOCHS, LEARNING_RATE, device, model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "# --- Final Evaluation and Visualization ---\n",
    "print(\"\\n--- Performing Final Evaluation on Test Set ---\")\n",
    "final_metrics = evaluate_model(trained_model, test_loader, device, num_classes, class_names)\n",
    "\n",
    "if 'confusion_matrix' in final_metrics:\n",
    "    plot_confusion_matrix(final_metrics['confusion_matrix'], class_names,\n",
    "                            filename=f'{MODEL_NAME}_confusion_matrix.png',\n",
    "                            figsize=(25,25))\n",
    "\n",
    "visualize_misclassified(trained_model, test_loader, device, class_names,\n",
    "                        num_images=25,\n",
    "                        filename_prefix=f'{MODEL_NAME}_misclassified')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_history, label='Train Accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title(f'{MODEL_NAME.upper()} Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f'{MODEL_NAME}_accuracy_history.png')\n",
    "print(f\"Accuracy history plot saved to {MODEL_NAME}_accuracy_history.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab149dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
