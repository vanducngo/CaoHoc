{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d21c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import matplotlib.pyplot as plt # For accuracy plot\n",
    "from tqdm import tqdm # For progress bars\n",
    "\n",
    "# Import from other modules\n",
    "from data_loader import get_cifar100_loaders\n",
    "from evaluation_utils import (evaluate_model, plot_confusion_matrix,\n",
    "                              visualize_misclassified, get_cifar100_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b62142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs, learning_rate, device, model_name=\"vit\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # AdamW is often recommended for Transformers\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Adjust step_size for 20 epochs\n",
    "\n",
    "    model.to(device)\n",
    "    best_accuracy = 0.0\n",
    "    model_save_path = f'{model_name}_cifar100_best.pth'\n",
    "\n",
    "    train_acc_history = []\n",
    "    test_acc_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for i, (inputs, labels) in enumerate(train_iterator):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            train_iterator.set_postfix(loss=loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc_train = 100.0 * correct_train / total_train\n",
    "        train_acc_history.append(epoch_acc_train)\n",
    "\n",
    "        model.eval()\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        test_iterator = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_iterator:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_acc_test = 100.0 * correct_test / total_test\n",
    "        test_acc_history.append(epoch_acc_test)\n",
    "        end_time = time.time()\n",
    "        epoch_duration = end_time - start_time\n",
    "\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | '\n",
    "              f'Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc_train:.2f}% | '\n",
    "              f'Test Acc: {epoch_acc_test:.2f}% | LR: {current_lr:.6f} | '\n",
    "              f'Duration: {epoch_duration:.2f}s')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch_acc_test > best_accuracy:\n",
    "            best_accuracy = epoch_acc_test\n",
    "            try:\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                print(f'>>> Best model saved to {model_save_path} with Test Accuracy: {best_accuracy:.2f}%')\n",
    "            except Exception as e:\n",
    "                 print(f\"Lỗi khi lưu model: {e}\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    print(f'Best Validation Accuracy achieved during training: {best_accuracy:.2f}%')\n",
    "\n",
    "    print(f\"Loading best model state from {model_save_path} for final evaluation...\")\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(model_save_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load best model state: {e}. Evaluating with the final model state.\")\n",
    "\n",
    "    return model, train_acc_history, test_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03db3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cuda\n",
      "Đang tải dữ liệu CIFAR-100 (resize: 224x224)...\n",
      "Đã tải xong CIFAR-100.\n",
      "Số lượng ảnh Train: 50000\n",
      "Số lượng ảnh Test: 10000\n",
      "Kích thước ảnh: 224x224\n",
      "Sử dụng Data Augmentation: True\n",
      "Khởi tạo 7_ViT_B_16 pre-trained model...\n",
      "Replaced ViT classifier head (model.heads.head) with Linear(768, 100)\n",
      "Bắt đầu fine-tuning 7_ViT_B_16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]:   1%|▏         | 41/3125 [00:16<20:34,  2.50it/s, loss=4.8]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m     exit()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBắt đầu fine-tuning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m trained_model, train_history, test_history \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[1;32m     57\u001b[0m     model, train_loader, test_loader, NUM_EPOCHS, LEARNING_RATE, device, model_name\u001b[38;5;241m=\u001b[39mMODEL_NAME\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Performing Final Evaluation on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m final_metrics \u001b[38;5;241m=\u001b[39m evaluate_model(trained_model, test_loader, device, num_classes, class_names)\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, num_epochs, learning_rate, device, model_name)\u001b[0m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 32\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m total_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32     \n",
    "LEARNING_RATE = 0.001   \n",
    "IMG_SIZE = 224      \n",
    "USE_AUGMENTATION = True\n",
    "DATA_DIR = './data_cifar100'\n",
    "NUM_WORKERS = 4\n",
    "MODEL_NAME = \"7_ViT_B_16\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sử dụng thiết bị: {device}\")\n",
    "\n",
    "class_names = get_cifar100_class_names(DATA_DIR)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Đang tải dữ liệu CIFAR-100 (resize: {IMG_SIZE}x{IMG_SIZE})...\")\n",
    "train_loader, test_loader, _ = get_cifar100_loaders(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_dir=DATA_DIR,\n",
    "    img_size=IMG_SIZE,\n",
    "    use_augmentation=USE_AUGMENTATION,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "if train_loader is None:\n",
    "    print(\"Không thể tải dữ liệu. Kết thúc chương trình.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Khởi tạo {MODEL_NAME} pre-trained model...\")\n",
    "# Load a pre-trained Vision Transformer model\n",
    "try:\n",
    "    weights = models.ViT_B_16_Weights.IMAGENET1K_V1\n",
    "    model = models.vit_b_16(weights=weights)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model {MODEL_NAME}: {e}\")\n",
    "    print(\"Make sure torchvision is up to date (pip install --upgrade torchvision)\")\n",
    "    exit()\n",
    "\n",
    "# Adapt the classifier head\n",
    "# In ViT, the classifier head is usually called 'heads' or 'head'\n",
    "if hasattr(model, 'heads') and isinstance(model.heads, nn.Sequential) and hasattr(model.heads, 'head'):\n",
    "    num_ftrs = model.heads.head.in_features\n",
    "    model.heads.head = nn.Linear(num_ftrs, num_classes)\n",
    "    print(f\"Replaced ViT classifier head (model.heads.head) with Linear({num_ftrs}, {num_classes})\")\n",
    "elif hasattr(model, 'head') and isinstance(model.head, nn.Linear): # For some simpler ViT implementations or older torchvision\n",
    "    num_ftrs = model.head.in_features\n",
    "    model.head = nn.Linear(num_ftrs, num_classes)\n",
    "    print(f\"Replaced ViT classifier head (model.head) with Linear({num_ftrs}, {num_classes})\")\n",
    "else:\n",
    "    print(\"Could not automatically find and replace the ViT classifier head.\")\n",
    "    print(\"Please inspect the model structure (print(model)) and adapt manually.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "print(f\"Bắt đầu fine-tuning {MODEL_NAME}...\")\n",
    "trained_model, train_history, test_history = train_model(\n",
    "    model, train_loader, test_loader, NUM_EPOCHS, LEARNING_RATE, device, model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Performing Final Evaluation on {MODEL_NAME} ---\")\n",
    "final_metrics = evaluate_model(trained_model, test_loader, device, num_classes, class_names)\n",
    "\n",
    "if 'confusion_matrix' in final_metrics:\n",
    "    plot_confusion_matrix(final_metrics['confusion_matrix'], class_names,\n",
    "                            filename=f'{MODEL_NAME}_confusion_matrix.png',\n",
    "                            figsize=(25, 25))\n",
    "\n",
    "visualize_misclassified(trained_model, test_loader, device, class_names,\n",
    "                        num_images=25,\n",
    "                        filename_prefix=f'{MODEL_NAME}_misclassified')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_history, label='Train Accuracy')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title(f'{MODEL_NAME.upper()} Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f'{MODEL_NAME}_accuracy_history.png')\n",
    "print(f\"Accuracy history plot saved to {MODEL_NAME}_accuracy_history.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
