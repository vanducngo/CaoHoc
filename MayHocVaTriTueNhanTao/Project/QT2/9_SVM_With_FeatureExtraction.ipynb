{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2befff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
    "                             confusion_matrix as sklearn_confusion_matrix, classification_report)\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import get_cifar100_loaders\n",
    "from evaluation_utils import get_cifar100_class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ad4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sklearn_confusion_matrix(cm, class_names, figsize=(20,20), filename='svm_confusion_matrix.png', normalize=False):\n",
    "    if normalize:\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_to_plot = cm_normalized\n",
    "        fmt = '.2f'\n",
    "        title = 'Normalized Confusion Matrix (SVM)'\n",
    "    else:\n",
    "        cm_to_plot = cm\n",
    "        fmt = 'd'\n",
    "        title = 'Confusion Matrix, without normalization (SVM)'\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cm_to_plot, annot=False, fmt=fmt, cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names) # annot=False for 100 classes\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(filename)\n",
    "        print(f\"Confusion matrix saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving SVM confusion matrix: {e}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47588968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data_loader, model, device):\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    print(\"Extracting features...\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            features_list.append(outputs.cpu().numpy())\n",
    "            labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23caf3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cpu for feature extraction\n",
      "Files already downloaded and verified\n",
      "Đang tải dữ liệu CIFAR-100 (resize: 224x224)...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Đã tải xong CIFAR-100.\n",
      "Số lượng ảnh Train: 50000\n",
      "Số lượng ảnh Test: 10000\n",
      "Kích thước ảnh: 224x224\n",
      "Sử dụng Data Augmentation: True\n",
      "Loading resnet18 as feature extractor...\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/391 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  0%|          | 0/391 [00:08<?, ?it/s]  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torchvision/ops/roi_align.py\", line 4, in <module>\n",
      "    import torch._dynamo\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 2, in <module>\n",
      "    from . import allowed_functions, convert_frame, eval_frame, resume_execution\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/allowed_functions.py\", line 30, in <module>\n",
      "    from .utils import hashable, is_safe_constant, NP_SUPPORTED_MODULES\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/_dynamo/utils.py\", line 89, in <module>\n",
      "    import torch.fx.experimental.symbolic_shapes\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/torch/fx/experimental/symbolic_shapes.py\", line 38, in <module>\n",
      "    from torch.utils._sympy.functions import FloorDiv, Mod, IsNonOverlappingAndDenseIndicator\n",
      "  File \"/opt/anaconda3/lib/pyt\n",
      "hon3.12/site-packages/torch/utils/_sympy/functions.py\", line 1, in <module>\n",
      "    import sympy\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/__init__.py\", line 30, in <module>\n",
      "    from sympy.core.cache import lazy_function\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/core/__init__.py\", line 9, in <module>\n",
      "    from .expr import Expr, AtomicExpr, UnevaluatedExpr\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/core/expr.py\", line 4159, in <module>\n",
      "    from .mul import Mul\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/core/mul.py\", line 2193, in <module>\n",
      "    from .numbers import Rational\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/core/numbers.py\", line 4582, in <module>\n",
      "    from .power import Pow, integer_nthroot\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/core/power.py\", line 11, in <module>\n",
      "    from .function import (expand_complex, expand_multinomial,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/core/function.py\", line 3385, in <module>\n",
      "    from .symbol import Dummy, Symbol\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/core/symbol.py\", line 14, in <module>\n",
      "    from sympy.logic.boolalg import Boolean\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sympy/logic/__init__.py\", line 1, in <module>\n",
      "    from .boolalg import (to_cnf, to_dnf, to_nnf, And, Or, Not, Xor, Nand, Nor, Implies,\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 991, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1124, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 753, in _compile_bytecode\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# --- 3. Extract Features ---\u001b[39;00m\n\u001b[32m     43\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m train_features, train_labels = \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m test_features, test_labels = extract_features(test_loader, feature_extractor, device)\n\u001b[32m     46\u001b[39m extraction_time = time.time() - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(data_loader, model, device)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExtracting features...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:439\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:387\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1040\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1033\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1036\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1042\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 224\n",
    "DATA_DIR = './data_cifar100'\n",
    "NUM_WORKERS = 4\n",
    "FEATURE_EXTRACTOR_MODEL_NAME = \"resnet18\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sử dụng thiết bị: {device} for feature extraction\")\n",
    "\n",
    "class_names = get_cifar100_class_names(DATA_DIR)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Đang tải dữ liệu CIFAR-100 (resize: {IMG_SIZE}x{IMG_SIZE})...\")\n",
    "train_loader, test_loader, _ = get_cifar100_loaders(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    data_dir=DATA_DIR,\n",
    "    img_size=IMG_SIZE,\n",
    "    use_augmentation=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "if train_loader is None:\n",
    "    print(\"Không thể tải dữ liệu. Kết thúc chương trình.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Load Pre-trained Model as Feature Extractor ---\n",
    "print(f\"Loading {FEATURE_EXTRACTOR_MODEL_NAME} as feature extractor...\")\n",
    "if FEATURE_EXTRACTOR_MODEL_NAME == \"resnet18\":\n",
    "    weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "    feature_extractor = models.resnet18(weights=weights)\n",
    "    # Remove the final fully connected layer (the classifier)\n",
    "    feature_extractor.fc = nn.Identity() # Replace with an identity layer\n",
    "elif FEATURE_EXTRACTOR_MODEL_NAME == \"resnet50\":\n",
    "    weights = models.ResNet50_Weights.IMAGENET1K_V2 # Or V1\n",
    "    feature_extractor = models.resnet50(weights=weights)\n",
    "    feature_extractor.fc = nn.Identity()\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported feature extractor: {FEATURE_EXTRACTOR_MODEL_NAME}\")\n",
    "\n",
    "feature_extractor.to(device)\n",
    "feature_extractor.eval() # Set to evaluation mode\n",
    "\n",
    "# --- 3. Extract Features ---\n",
    "start_time = time.time()\n",
    "train_features, train_labels = extract_features(train_loader, feature_extractor, device)\n",
    "test_features, test_labels = extract_features(test_loader, feature_extractor, device)\n",
    "extraction_time = time.time() - start_time\n",
    "print(f\"Feature extraction completed. Time taken: {extraction_time:.2f}s\")\n",
    "print(f\"Shape of training features: {train_features.shape}\") # Should be (50000, num_output_features_from_cnn)\n",
    "print(f\"Shape of test features: {test_features.shape}\")     # Should be (10000, num_output_features_from_cnn)\n",
    "\n",
    "# --- 4. Train SVM Classifier ---\n",
    "print(\"Training SVM classifier...\")\n",
    "start_time = time.time()\n",
    "\n",
    "svm_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf', C=1.0, gamma='scale', decision_function_shape='ovr', random_state=42, verbose=True)\n",
    ")\n",
    "\n",
    "svm_pipeline.fit(train_features, train_labels)\n",
    "training_time = time.time() - start_time\n",
    "print(f\"SVM training completed. Time taken: {training_time:.2f}s\")\n",
    "\n",
    "# --- 5. Evaluate SVM ---\n",
    "print(\"Evaluating SVM on the test set...\")\n",
    "start_time = time.time()\n",
    "test_predictions = svm_pipeline.predict(test_features)\n",
    "evaluation_time = time.time() - start_time\n",
    "print(f\"SVM evaluation completed. Time taken: {evaluation_time:.2f}s\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "# For Top-5 with SVM, we'd need decision_function scores and then sort, which is more complex\n",
    "# For now, focusing on Top-1 as SVM doesn't directly give Top-N probabilities like NNs.\n",
    "\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    test_labels, test_predictions, average='macro', zero_division=0\n",
    ")\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "    test_labels, test_predictions, average='weighted', zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(test_labels, test_predictions, target_names=class_names, zero_division=0))\n",
    "\n",
    "print(f\"\\nSVM Evaluation Summary:\")\n",
    "print(f\"  Top-1 Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  Macro Avg - Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1-Score: {f1_macro:.4f}\")\n",
    "print(f\"  Weighted Avg - Precision: {precision_weighted:.4f}, Recall: {recall_weighted:.4f}, F1-Score: {f1_weighted:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = sklearn_confusion_matrix(test_labels, test_predictions, labels=range(num_classes))\n",
    "plot_sklearn_confusion_matrix(cm, class_names,\n",
    "                                filename=f'svm_{FEATURE_EXTRACTOR_MODEL_NAME}_features_cm.png',\n",
    "                                fiCgsize=(25,25)) # Adjust size if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1167e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
